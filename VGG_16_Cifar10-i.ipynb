{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG-16 Cifar10",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ojas29092000/cifar10/blob/main/VGG_16_Cifar10-i.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XnHEyClMlFL",
        "outputId": "7caae971-ddbb-4878-f265-d2542ad5507b"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o15UTMy5OGgJ"
      },
      "source": [
        "import tensorflow.keras\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, Convolution2D\n",
        "from tensorflow.keras import backend as K\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras import optimizers\n",
        "import numpy as np\n",
        "from keras.layers.core import Lambda\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import regularizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtYvjDE6SYZ1"
      },
      "source": [
        "CIFAR-10  is an established computer-vision dataset used for object recognition. It is a subset of the 80 million tiny images dataset and consists of 60,000 32x32 color images containing one of 10 object classes, with 6000 images per class. It was collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton.\n",
        "\n",
        "Kaggle is hosting a CIFAR-10 leaderboard for the machine learning community to use for fun and practice. You can see how your approach compares to the latest research methods on Rodrigo Benenson's classification results page."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PF72eSkIOTFY"
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jur4ld9GOnUq",
        "outputId": "37d320ba-887f-44dd-bf41-3845a65b75a5"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wx90OiFeQkgz",
        "outputId": "f2ba1ed4-6825-4b6e-cfb1-8f6380e3797b"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlHM95afQphB"
      },
      "source": [
        "model = Sequential()\n",
        "weight_decay = 0.0005\n",
        "x_shape = [32,32,3]\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same', input_shape=x_shape, kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512,kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHUlVSfFQ2vv",
        "outputId": "c1acf3be-86c8-4b6c-bf49-91c6bb6edb10"
      },
      "source": [
        "learning_rate = 0.1\n",
        "lr_decay = 1e-6\n",
        "lr_drop = 20\n",
        "\n",
        "sgd = optimizers.SGD(lr=learning_rate, decay=lr_decay, momentum=0.9, nesterov=True)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvNo2qmcSM9d"
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    \n",
        "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "    samplewise_center=False,  # set each sample mean to 0\n",
        "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "    samplewise_std_normalization=False,  # divide each input by its std\n",
        "    zca_whitening=False,  # apply ZCA whitening\n",
        "    rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "    horizontal_flip=True,  # randomly flip images\n",
        "    vertical_flip=False)  # randomly flip images\n",
        "# (std, mean, and principal components if ZCA whitening is applied)."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VqAuA2eSRvE"
      },
      "source": [
        "def lr_scheduler(epoch):\n",
        "            return learning_rate * (0.5 ** (epoch // lr_drop))\n",
        "    \n",
        "reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YNiYucTSUop",
        "outputId": "458b7967-0f8a-411f-ba6d-431e27929b26"
      },
      "source": [
        "batch_size = 128\n",
        "maxepoches = 100\n",
        "\n",
        "\n",
        "history = model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                               batch_size=batch_size),\n",
        "                                  \n",
        "                                steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "                                epochs=maxepoches,\n",
        "                                validation_data=(x_test, y_test),callbacks=[reduce_lr], verbose=1)\n",
        "\n",
        "model.save_weights('cifar10vgg.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "390/390 [==============================] - 100s 170ms/step - loss: 21.5806 - accuracy: 0.1906 - val_loss: 18.7426 - val_accuracy: 0.0985 - lr: 0.1000\n",
            "Epoch 2/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 13.0361 - accuracy: 0.3004 - val_loss: 10.0513 - val_accuracy: 0.1395 - lr: 0.1000\n",
            "Epoch 3/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 6.8669 - accuracy: 0.3926 - val_loss: 5.4012 - val_accuracy: 0.3138 - lr: 0.1000\n",
            "Epoch 4/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 3.9707 - accuracy: 0.4953 - val_loss: 3.3856 - val_accuracy: 0.4530 - lr: 0.1000\n",
            "Epoch 5/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 2.6476 - accuracy: 0.5592 - val_loss: 2.2800 - val_accuracy: 0.5906 - lr: 0.1000\n",
            "Epoch 6/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 2.0371 - accuracy: 0.6045 - val_loss: 1.7818 - val_accuracy: 0.6498 - lr: 0.1000\n",
            "Epoch 7/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 1.7360 - accuracy: 0.6397 - val_loss: 1.6524 - val_accuracy: 0.6381 - lr: 0.1000\n",
            "Epoch 8/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 1.6291 - accuracy: 0.6542 - val_loss: 1.7296 - val_accuracy: 0.6256 - lr: 0.1000\n",
            "Epoch 9/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 1.5487 - accuracy: 0.6751 - val_loss: 1.6245 - val_accuracy: 0.6578 - lr: 0.1000\n",
            "Epoch 10/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 1.5181 - accuracy: 0.6864 - val_loss: 1.6500 - val_accuracy: 0.6541 - lr: 0.1000\n",
            "Epoch 11/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 1.5217 - accuracy: 0.6888 - val_loss: 1.6138 - val_accuracy: 0.6659 - lr: 0.1000\n",
            "Epoch 12/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 1.5046 - accuracy: 0.7005 - val_loss: 1.4620 - val_accuracy: 0.7109 - lr: 0.1000\n",
            "Epoch 13/100\n",
            "390/390 [==============================] - 63s 160ms/step - loss: 1.5041 - accuracy: 0.7044 - val_loss: 1.5272 - val_accuracy: 0.6966 - lr: 0.1000\n",
            "Epoch 14/100\n",
            "390/390 [==============================] - 63s 160ms/step - loss: 1.5113 - accuracy: 0.7072 - val_loss: 1.6889 - val_accuracy: 0.6407 - lr: 0.1000\n",
            "Epoch 15/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 1.5072 - accuracy: 0.7116 - val_loss: 1.5871 - val_accuracy: 0.6782 - lr: 0.1000\n",
            "Epoch 16/100\n",
            "390/390 [==============================] - 62s 160ms/step - loss: 1.5189 - accuracy: 0.7169 - val_loss: 1.6582 - val_accuracy: 0.6744 - lr: 0.1000\n",
            "Epoch 17/100\n",
            "390/390 [==============================] - 67s 171ms/step - loss: 1.5210 - accuracy: 0.7159 - val_loss: 1.5668 - val_accuracy: 0.7036 - lr: 0.1000\n",
            "Epoch 18/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 1.5253 - accuracy: 0.7191 - val_loss: 1.6318 - val_accuracy: 0.6826 - lr: 0.1000\n",
            "Epoch 19/100\n",
            "390/390 [==============================] - 63s 160ms/step - loss: 1.5338 - accuracy: 0.7219 - val_loss: 1.5148 - val_accuracy: 0.7235 - lr: 0.1000\n",
            "Epoch 20/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 1.5369 - accuracy: 0.7213 - val_loss: 1.5082 - val_accuracy: 0.7359 - lr: 0.1000\n",
            "Epoch 21/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 1.3623 - accuracy: 0.7632 - val_loss: 1.2202 - val_accuracy: 0.7951 - lr: 0.0500\n",
            "Epoch 22/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 1.2696 - accuracy: 0.7716 - val_loss: 1.2206 - val_accuracy: 0.7712 - lr: 0.0500\n",
            "Epoch 23/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 1.2485 - accuracy: 0.7711 - val_loss: 1.1234 - val_accuracy: 0.8083 - lr: 0.0500\n",
            "Epoch 24/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 1.2369 - accuracy: 0.7751 - val_loss: 1.1390 - val_accuracy: 0.8080 - lr: 0.0500\n",
            "Epoch 25/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 1.2332 - accuracy: 0.7779 - val_loss: 1.1911 - val_accuracy: 0.7854 - lr: 0.0500\n",
            "Epoch 26/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 1.2298 - accuracy: 0.7771 - val_loss: 1.1687 - val_accuracy: 0.7979 - lr: 0.0500\n",
            "Epoch 27/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 1.2370 - accuracy: 0.7789 - val_loss: 1.3334 - val_accuracy: 0.7550 - lr: 0.0500\n",
            "Epoch 28/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 1.2476 - accuracy: 0.7797 - val_loss: 1.5493 - val_accuracy: 0.7214 - lr: 0.0500\n",
            "Epoch 29/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 1.2447 - accuracy: 0.7828 - val_loss: 1.1392 - val_accuracy: 0.8140 - lr: 0.0500\n",
            "Epoch 30/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 1.2523 - accuracy: 0.7830 - val_loss: 1.2559 - val_accuracy: 0.7773 - lr: 0.0500\n",
            "Epoch 31/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 1.2557 - accuracy: 0.7847 - val_loss: 1.1435 - val_accuracy: 0.8214 - lr: 0.0500\n",
            "Epoch 32/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 1.2712 - accuracy: 0.7808 - val_loss: 1.1879 - val_accuracy: 0.8124 - lr: 0.0500\n",
            "Epoch 33/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 1.2879 - accuracy: 0.7790 - val_loss: 1.3543 - val_accuracy: 0.7687 - lr: 0.0500\n",
            "Epoch 34/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 1.2855 - accuracy: 0.7820 - val_loss: 1.3620 - val_accuracy: 0.7607 - lr: 0.0500\n",
            "Epoch 35/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 1.2818 - accuracy: 0.7819 - val_loss: 1.2304 - val_accuracy: 0.8037 - lr: 0.0500\n",
            "Epoch 36/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 1.2747 - accuracy: 0.7881 - val_loss: 1.3242 - val_accuracy: 0.7732 - lr: 0.0500\n",
            "Epoch 37/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 1.2790 - accuracy: 0.7862 - val_loss: 1.4679 - val_accuracy: 0.7221 - lr: 0.0500\n",
            "Epoch 38/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 1.2788 - accuracy: 0.7882 - val_loss: 1.1881 - val_accuracy: 0.8166 - lr: 0.0500\n",
            "Epoch 39/100\n",
            "390/390 [==============================] - 67s 171ms/step - loss: 1.2823 - accuracy: 0.7886 - val_loss: 1.2669 - val_accuracy: 0.8048 - lr: 0.0500\n",
            "Epoch 40/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 1.2872 - accuracy: 0.7882 - val_loss: 1.1833 - val_accuracy: 0.8220 - lr: 0.0500\n",
            "Epoch 41/100\n",
            "390/390 [==============================] - 63s 162ms/step - loss: 1.1569 - accuracy: 0.8216 - val_loss: 1.0846 - val_accuracy: 0.8396 - lr: 0.0250\n",
            "Epoch 42/100\n",
            "390/390 [==============================] - 63s 162ms/step - loss: 1.0765 - accuracy: 0.8330 - val_loss: 1.0050 - val_accuracy: 0.8506 - lr: 0.0250\n",
            "Epoch 43/100\n",
            "390/390 [==============================] - 63s 162ms/step - loss: 1.0476 - accuracy: 0.8322 - val_loss: 0.9703 - val_accuracy: 0.8510 - lr: 0.0250\n",
            "Epoch 44/100\n",
            "390/390 [==============================] - 63s 162ms/step - loss: 1.0274 - accuracy: 0.8336 - val_loss: 0.9305 - val_accuracy: 0.8613 - lr: 0.0250\n",
            "Epoch 45/100\n",
            "390/390 [==============================] - 63s 162ms/step - loss: 1.0099 - accuracy: 0.8345 - val_loss: 0.9649 - val_accuracy: 0.8443 - lr: 0.0250\n",
            "Epoch 46/100\n",
            "390/390 [==============================] - 63s 162ms/step - loss: 0.9983 - accuracy: 0.8359 - val_loss: 0.9770 - val_accuracy: 0.8420 - lr: 0.0250\n",
            "Epoch 47/100\n",
            "390/390 [==============================] - 63s 162ms/step - loss: 1.0034 - accuracy: 0.8337 - val_loss: 0.9588 - val_accuracy: 0.8487 - lr: 0.0250\n",
            "Epoch 48/100\n",
            "390/390 [==============================] - 63s 162ms/step - loss: 1.0003 - accuracy: 0.8350 - val_loss: 0.9029 - val_accuracy: 0.8666 - lr: 0.0250\n",
            "Epoch 49/100\n",
            "390/390 [==============================] - 63s 162ms/step - loss: 0.9967 - accuracy: 0.8373 - val_loss: 0.9503 - val_accuracy: 0.8494 - lr: 0.0250\n",
            "Epoch 50/100\n",
            "390/390 [==============================] - 63s 162ms/step - loss: 1.0075 - accuracy: 0.8325 - val_loss: 0.9632 - val_accuracy: 0.8444 - lr: 0.0250\n",
            "Epoch 51/100\n",
            "390/390 [==============================] - 63s 162ms/step - loss: 1.0001 - accuracy: 0.8377 - val_loss: 0.9649 - val_accuracy: 0.8479 - lr: 0.0250\n",
            "Epoch 52/100\n",
            "390/390 [==============================] - 67s 171ms/step - loss: 1.0066 - accuracy: 0.8347 - val_loss: 0.9717 - val_accuracy: 0.8474 - lr: 0.0250\n",
            "Epoch 53/100\n",
            "390/390 [==============================] - 63s 162ms/step - loss: 1.0074 - accuracy: 0.8389 - val_loss: 0.9447 - val_accuracy: 0.8546 - lr: 0.0250\n",
            "Epoch 54/100\n",
            "390/390 [==============================] - 63s 162ms/step - loss: 1.0083 - accuracy: 0.8369 - val_loss: 0.9335 - val_accuracy: 0.8616 - lr: 0.0250\n",
            "Epoch 55/100\n",
            "390/390 [==============================] - 63s 162ms/step - loss: 1.0082 - accuracy: 0.8399 - val_loss: 0.9286 - val_accuracy: 0.8626 - lr: 0.0250\n",
            "Epoch 56/100\n",
            "390/390 [==============================] - 64s 163ms/step - loss: 1.0129 - accuracy: 0.8386 - val_loss: 1.1765 - val_accuracy: 0.7872 - lr: 0.0250\n",
            "Epoch 57/100\n",
            "390/390 [==============================] - 63s 162ms/step - loss: 1.0040 - accuracy: 0.8391 - val_loss: 1.0309 - val_accuracy: 0.8340 - lr: 0.0250\n",
            "Epoch 58/100\n",
            "390/390 [==============================] - 63s 162ms/step - loss: 1.0101 - accuracy: 0.8370 - val_loss: 1.0317 - val_accuracy: 0.8324 - lr: 0.0250\n",
            "Epoch 59/100\n",
            "390/390 [==============================] - 63s 162ms/step - loss: 0.9992 - accuracy: 0.8427 - val_loss: 0.9603 - val_accuracy: 0.8513 - lr: 0.0250\n",
            "Epoch 60/100\n",
            "390/390 [==============================] - 63s 162ms/step - loss: 1.0011 - accuracy: 0.8425 - val_loss: 1.0008 - val_accuracy: 0.8375 - lr: 0.0250\n",
            "Epoch 61/100\n",
            "390/390 [==============================] - 63s 162ms/step - loss: 0.9182 - accuracy: 0.8664 - val_loss: 0.8745 - val_accuracy: 0.8762 - lr: 0.0125\n",
            "Epoch 62/100\n",
            "390/390 [==============================] - 63s 162ms/step - loss: 0.8701 - accuracy: 0.8746 - val_loss: 0.8513 - val_accuracy: 0.8756 - lr: 0.0125\n",
            "Epoch 63/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 0.8405 - accuracy: 0.8776 - val_loss: 0.7967 - val_accuracy: 0.8889 - lr: 0.0125\n",
            "Epoch 64/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 0.8266 - accuracy: 0.8791 - val_loss: 0.7971 - val_accuracy: 0.8849 - lr: 0.0125\n",
            "Epoch 65/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 0.8122 - accuracy: 0.8780 - val_loss: 0.9067 - val_accuracy: 0.8508 - lr: 0.0125\n",
            "Epoch 66/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 0.7974 - accuracy: 0.8796 - val_loss: 0.7804 - val_accuracy: 0.8812 - lr: 0.0125\n",
            "Epoch 67/100\n",
            "390/390 [==============================] - 63s 162ms/step - loss: 0.7917 - accuracy: 0.8792 - val_loss: 0.7726 - val_accuracy: 0.8861 - lr: 0.0125\n",
            "Epoch 68/100\n",
            "390/390 [==============================] - 63s 162ms/step - loss: 0.7882 - accuracy: 0.8787 - val_loss: 0.8512 - val_accuracy: 0.8626 - lr: 0.0125\n",
            "Epoch 69/100\n",
            "390/390 [==============================] - 67s 171ms/step - loss: 0.7826 - accuracy: 0.8784 - val_loss: 0.7827 - val_accuracy: 0.8794 - lr: 0.0125\n",
            "Epoch 70/100\n",
            "390/390 [==============================] - 63s 162ms/step - loss: 0.7808 - accuracy: 0.8782 - val_loss: 0.7932 - val_accuracy: 0.8760 - lr: 0.0125\n",
            "Epoch 71/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 0.7780 - accuracy: 0.8791 - val_loss: 0.8950 - val_accuracy: 0.8471 - lr: 0.0125\n",
            "Epoch 72/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 0.7847 - accuracy: 0.8778 - val_loss: 0.7953 - val_accuracy: 0.8765 - lr: 0.0125\n",
            "Epoch 73/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 0.7794 - accuracy: 0.8785 - val_loss: 0.9838 - val_accuracy: 0.8177 - lr: 0.0125\n",
            "Epoch 74/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 0.7828 - accuracy: 0.8755 - val_loss: 0.7517 - val_accuracy: 0.8883 - lr: 0.0125\n",
            "Epoch 75/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 0.7802 - accuracy: 0.8767 - val_loss: 0.8342 - val_accuracy: 0.8624 - lr: 0.0125\n",
            "Epoch 76/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 0.7848 - accuracy: 0.8771 - val_loss: 0.7964 - val_accuracy: 0.8751 - lr: 0.0125\n",
            "Epoch 77/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 0.7743 - accuracy: 0.8817 - val_loss: 0.8400 - val_accuracy: 0.8612 - lr: 0.0125\n",
            "Epoch 78/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 0.7775 - accuracy: 0.8801 - val_loss: 0.7721 - val_accuracy: 0.8833 - lr: 0.0125\n",
            "Epoch 79/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 0.7826 - accuracy: 0.8784 - val_loss: 0.9598 - val_accuracy: 0.8299 - lr: 0.0125\n",
            "Epoch 80/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 0.7793 - accuracy: 0.8802 - val_loss: 0.9228 - val_accuracy: 0.8379 - lr: 0.0125\n",
            "Epoch 81/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 0.7162 - accuracy: 0.8992 - val_loss: 0.7312 - val_accuracy: 0.8930 - lr: 0.0063\n",
            "Epoch 82/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 0.6848 - accuracy: 0.9059 - val_loss: 0.7062 - val_accuracy: 0.9010 - lr: 0.0063\n",
            "Epoch 83/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 0.6701 - accuracy: 0.9075 - val_loss: 0.6768 - val_accuracy: 0.9063 - lr: 0.0063\n",
            "Epoch 84/100\n",
            "390/390 [==============================] - 63s 162ms/step - loss: 0.6541 - accuracy: 0.9105 - val_loss: 0.6731 - val_accuracy: 0.9058 - lr: 0.0063\n",
            "Epoch 85/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 0.6488 - accuracy: 0.9097 - val_loss: 0.6866 - val_accuracy: 0.9022 - lr: 0.0063\n",
            "Epoch 86/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 0.6332 - accuracy: 0.9128 - val_loss: 0.6822 - val_accuracy: 0.8975 - lr: 0.0063\n",
            "Epoch 87/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 0.6298 - accuracy: 0.9130 - val_loss: 0.6870 - val_accuracy: 0.8964 - lr: 0.0063\n",
            "Epoch 88/100\n",
            "390/390 [==============================] - 63s 162ms/step - loss: 0.6269 - accuracy: 0.9112 - val_loss: 0.6725 - val_accuracy: 0.8988 - lr: 0.0063\n",
            "Epoch 89/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 0.6192 - accuracy: 0.9123 - val_loss: 0.6771 - val_accuracy: 0.8965 - lr: 0.0063\n",
            "Epoch 90/100\n",
            "390/390 [==============================] - 63s 162ms/step - loss: 0.6117 - accuracy: 0.9144 - val_loss: 0.6731 - val_accuracy: 0.8973 - lr: 0.0063\n",
            "Epoch 91/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 0.6068 - accuracy: 0.9139 - val_loss: 0.6531 - val_accuracy: 0.9021 - lr: 0.0063\n",
            "Epoch 92/100\n",
            "390/390 [==============================] - 63s 162ms/step - loss: 0.6046 - accuracy: 0.9135 - val_loss: 0.6434 - val_accuracy: 0.9038 - lr: 0.0063\n",
            "Epoch 93/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 0.5994 - accuracy: 0.9139 - val_loss: 0.6959 - val_accuracy: 0.8910 - lr: 0.0063\n",
            "Epoch 94/100\n",
            "390/390 [==============================] - 63s 162ms/step - loss: 0.6005 - accuracy: 0.9120 - val_loss: 0.6274 - val_accuracy: 0.9061 - lr: 0.0063\n",
            "Epoch 95/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 0.5999 - accuracy: 0.9123 - val_loss: 0.6362 - val_accuracy: 0.9029 - lr: 0.0063\n",
            "Epoch 96/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 0.5966 - accuracy: 0.9131 - val_loss: 0.6551 - val_accuracy: 0.8962 - lr: 0.0063\n",
            "Epoch 97/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 0.5894 - accuracy: 0.9156 - val_loss: 0.6554 - val_accuracy: 0.8985 - lr: 0.0063\n",
            "Epoch 98/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 0.5954 - accuracy: 0.9132 - val_loss: 0.6458 - val_accuracy: 0.9014 - lr: 0.0063\n",
            "Epoch 99/100\n",
            "390/390 [==============================] - 63s 161ms/step - loss: 0.5912 - accuracy: 0.9128 - val_loss: 0.6686 - val_accuracy: 0.8929 - lr: 0.0063\n",
            "Epoch 100/100\n",
            "390/390 [==============================] - 63s 162ms/step - loss: 0.5960 - accuracy: 0.9107 - val_loss: 0.6273 - val_accuracy: 0.9034 - lr: 0.0063\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBcW50shuTbD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}