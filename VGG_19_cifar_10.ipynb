{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG-19 cifar-10",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ojas29092000/cifar10/blob/main/VGG_19_cifar_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a20YEO6yzuui"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "import os\n",
        "# print(os.listdir(\"../input\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-L0qzDtz6kM"
      },
      "source": [
        "#Import standard libraries\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "''' to learn more about itertools visit\n",
        "    https://medium.com/@jasonrigden/a-guide-to-python-itertools-82e5a306cdf8'''\n",
        "import itertools\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYj7yYF_0Bfr"
      },
      "source": [
        "#Import keras functions\n",
        "\n",
        "from tensorflow.keras import Sequential\n",
        "\n",
        "'''Since we are using transfer learning let's import the model that we want to implement.Let's use VGG 19(19 layers) and Resnet-50 (50 layers of residual units). \n",
        "Residual units allow us to add more layers onto the model without a degradation in accuracy.\n",
        "Let's try and compare the accuracy of the 2 models and see if the addtional layers do make a significant difference. '''\n",
        "\n",
        "from tensorflow.keras.applications import VGG19,ResNet50\n",
        "\n",
        "'Import the datagenerator to augment images'\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "'''Import the optimizers and leanring rate annealer (which will reduce the learning rate once a particular metric we choose(in this case validation error) \n",
        "does not reduce after a user defined number of epochs)'''\n",
        "from tensorflow.keras.optimizers import SGD,Adam\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "'Lastly import the final layers that will be added on top of the base model'\n",
        "from keras.layers import Flatten,Dense,BatchNormalization,Activation,Dropout\n",
        "\n",
        "'Import to_categorical from the keras utils package to one hot encode the labels'\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTLDW1zt0Rbg"
      },
      "source": [
        "from keras.datasets import cifar10"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGYhJpL70uvK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69963cf0-8874-4c67-9607-ebf853fb3f8d"
      },
      "source": [
        "#Divide the data in Train, Validation and Test Datasets\n",
        "'I had to turn the Internet setting to on to download load the dataset'\n",
        "(x_train,y_train),(x_test,y_test)=cifar10.load_data()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n",
            "170508288/170498071 [==============================] - 6s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNlT91Ug0yAg"
      },
      "source": [
        "x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=.3)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77zMu7aS02gY",
        "outputId": "03dfd70c-6283-4399-e8b1-84b1a2b0fedd"
      },
      "source": [
        "#Print the dimensions of the datasets to make sure everything's kosher\n",
        "\n",
        "print((x_train.shape,y_train.shape))\n",
        "print((x_val.shape,y_val.shape))\n",
        "print((x_test.shape,y_test.shape))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "((35000, 32, 32, 3), (35000, 1))\n",
            "((15000, 32, 32, 3), (15000, 1))\n",
            "((10000, 32, 32, 3), (10000, 1))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMU78Aq305Sg"
      },
      "source": [
        "#One hot encode the labels.Since we have 10 classes we should expect the shape[1] of y_train,y_val and y_test to change from 1 to 10\n",
        "\n",
        "y_train=to_categorical(y_train)\n",
        "y_val=to_categorical(y_val)\n",
        "y_test=to_categorical(y_test)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UygveqbI08sf",
        "outputId": "37ae2308-38f6-48e7-bb6e-ab0d0418d524"
      },
      "source": [
        "# Lets print the dimensions one more time to see if things changed the way we expected\n",
        "\n",
        "print((x_train.shape,y_train.shape))\n",
        "print((x_val.shape,y_val.shape))\n",
        "print((x_test.shape,y_test.shape))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "((35000, 32, 32, 3), (35000, 10))\n",
            "((15000, 32, 32, 3), (15000, 10))\n",
            "((10000, 32, 32, 3), (10000, 10))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0E0XEYNV1DUP"
      },
      "source": [
        "#Data Augmentation Function: Let's define an instance of the ImageDataGenerator class and set the parameters.We have to instantiate for the Train,Validation and Test datasets\n",
        "train_generator = ImageDataGenerator(\n",
        "                                    rotation_range=2, \n",
        "                                    horizontal_flip=True,\n",
        "                                    zoom_range=.1 )\n",
        "\n",
        "val_generator = ImageDataGenerator(\n",
        "                                    rotation_range=2, \n",
        "                                    horizontal_flip=True,\n",
        "                                    zoom_range=.1)\n",
        "\n",
        "test_generator = ImageDataGenerator(\n",
        "                                    rotation_range=2, \n",
        "                                    horizontal_flip= True,\n",
        "                                    zoom_range=.1) "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3X0MB7P31Irv"
      },
      "source": [
        "#Fit the augmentation method to the data\n",
        "\n",
        "train_generator.fit(x_train)\n",
        "val_generator.fit(x_val)\n",
        "test_generator.fit(x_test)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDZJITTb1L1g"
      },
      "source": [
        "'''Learning Rate Annealer: The learning rate can be modified after a set number of epochs or after a certain condition is met. We will use the latter and change the learning rate if \n",
        "the validation error does not reduce after a set number of epochs. To do this we will use the patience parameter.'''\n",
        "\n",
        "lrr= ReduceLROnPlateau(\n",
        "                       monitor='val_acc', #Metric to be measured\n",
        "                       factor=.01, #Factor by which learning rate will be reduced\n",
        "                       patience=3,  #No. of epochs after which if there is no improvement in the val_acc, the learning rate is reduced\n",
        "                       min_lr=1e-5) #The minimum learning rate "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYKfKlxN1QNX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c47fa3a-d968-4de4-d959-6ee5c93bfdc4"
      },
      "source": [
        "#Build the model\n",
        "\n",
        "'The first base model used is VGG19. The pretrained weights from the imagenet challenge are used'\n",
        "base_model_1 = VGG19(include_top=False,weights='imagenet',input_shape=(32,32,3),classes=y_train.shape[1])\n",
        "'For the 2nd base model we will use Resnet 50 and compare the performance against the previous one.The hypothesis is that Resnet 50 should perform better because of its deeper architecture'\n",
        "base_model_2 = ResNet50(include_top=False,weights='imagenet',input_shape=(32,32,3),classes=y_train.shape[1])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 1s 0us/step\n",
            "80150528/80134624 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "94781440/94765736 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZnUbOvt1VXo"
      },
      "source": [
        "#Lets add the final layers to these base models where the actual classification is done in the dense layers\n",
        "\n",
        "model_1= Sequential()\n",
        "model_1.add(base_model_1) #Adds the base model (in this case vgg19 to model_1)\n",
        "model_1.add(Flatten()) #Since the output before the flatten layer is a matrix we have to use this function to get a vector of the form nX1 to feed it into the fully connected layers"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AisDks_61aWQ",
        "outputId": "4dece47a-aadf-4a4c-cda2-d8e78149ee2b"
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg19 (Functional)          (None, 1, 1, 512)         20024384  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,024,384\n",
            "Trainable params: 20,024,384\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3Gavpxs1dWP"
      },
      "source": [
        "#Add the Dense layers along with activation and batch normalization\n",
        "model_1.add(Dense(1024,activation=('relu'),input_dim=512))\n",
        "model_1.add(Dense(512,activation=('relu'))) \n",
        "model_1.add(Dense(256,activation=('relu'))) \n",
        "#model_1.add(Dropout(.3))#Adding a dropout layer that will randomly drop 30% of the weights\n",
        "model_1.add(Dense(128,activation=('relu')))\n",
        "#model_1.add(Dropout(.2))\n",
        "model_1.add(Dense(10,activation=('softmax'))) #This is the classification layer"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HE69BKLo1h9j",
        "outputId": "e38807f2-724e-400e-ce10-cfe463df6237"
      },
      "source": [
        "#Check final model summary\n",
        "model_1.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg19 (Functional)          (None, 1, 1, 512)         20024384  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              525312    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,240,010\n",
            "Trainable params: 21,240,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7U8GjK-c1kiL"
      },
      "source": [
        "batch_size= 70\n",
        "epochs=100"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ewf4w-Dr1prR",
        "outputId": "0b1b32bd-204c-41dd-f79f-954a56a446a3"
      },
      "source": [
        "learn_rate=.001\n",
        "\n",
        "sgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)\n",
        "adam=Adam(lr=learn_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noBSnBog17H5"
      },
      "source": [
        "#Compile the model\n",
        "#During model compiling the 3 main things we specify are loss function,optimizer and the metrics that need to be evaluated during the test and train processes.\n",
        "#Lets start by using the SGD optimizer\n",
        "#We will specify the loss as categoricl crossentropy since the labels are 1 hot encoded. IF we had integer labels,we'd have to use sparse categorical crossentropy as loss function.\n",
        "model_1.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7imxuuYb4bG5",
        "outputId": "5a942141-ae6c-4328-c08a-506cf2e58f93"
      },
      "source": [
        "model_1.fit_generator(train_generator.flow(x_train,y_train,batch_size=batch_size),\n",
        "                      epochs=epochs,\n",
        "                      steps_per_epoch=x_train.shape[0]//batch_size,\n",
        "                      validation_data=val_generator.flow(x_val,y_val,batch_size=batch_size),validation_steps=250,\n",
        "                      callbacks=[lrr],verbose=1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 1.5599 - accuracy: 0.4263WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 250 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "500/500 [==============================] - 109s 153ms/step - loss: 1.5599 - accuracy: 0.4263 - val_loss: 1.1819 - val_accuracy: 0.5823 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.8758 - accuracy: 0.6981WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 111ms/step - loss: 0.8758 - accuracy: 0.6981 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.6944 - accuracy: 0.7622WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 55s 111ms/step - loss: 0.6944 - accuracy: 0.7622 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.5924 - accuracy: 0.7982WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 55s 111ms/step - loss: 0.5924 - accuracy: 0.7982 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.5197 - accuracy: 0.8221WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 111ms/step - loss: 0.5197 - accuracy: 0.8221 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.4547 - accuracy: 0.8440WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 55s 111ms/step - loss: 0.4547 - accuracy: 0.8440 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.4097 - accuracy: 0.8593WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 55s 110ms/step - loss: 0.4097 - accuracy: 0.8593 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.3754 - accuracy: 0.8711WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 55s 111ms/step - loss: 0.3754 - accuracy: 0.8711 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.3354 - accuracy: 0.8829WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 55s 111ms/step - loss: 0.3354 - accuracy: 0.8829 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.3032 - accuracy: 0.8943WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 55s 111ms/step - loss: 0.3032 - accuracy: 0.8943 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.2766 - accuracy: 0.9045WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 55s 111ms/step - loss: 0.2766 - accuracy: 0.9045 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.2400 - accuracy: 0.9188WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 55s 111ms/step - loss: 0.2400 - accuracy: 0.9188 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.2264 - accuracy: 0.9215WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 55s 111ms/step - loss: 0.2264 - accuracy: 0.9215 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.2060 - accuracy: 0.9284WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 111ms/step - loss: 0.2060 - accuracy: 0.9284 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.1761 - accuracy: 0.9386WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 111ms/step - loss: 0.1761 - accuracy: 0.9386 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.1647 - accuracy: 0.9440WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 55s 111ms/step - loss: 0.1647 - accuracy: 0.9440 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.1506 - accuracy: 0.9479WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 55s 110ms/step - loss: 0.1506 - accuracy: 0.9479 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.1352 - accuracy: 0.9541WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 111ms/step - loss: 0.1352 - accuracy: 0.9541 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.1226 - accuracy: 0.9581WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 55s 111ms/step - loss: 0.1226 - accuracy: 0.9581 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.1095 - accuracy: 0.9629WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 111ms/step - loss: 0.1095 - accuracy: 0.9629 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.1048 - accuracy: 0.9644WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 55s 111ms/step - loss: 0.1048 - accuracy: 0.9644 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0947 - accuracy: 0.9682WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 55s 111ms/step - loss: 0.0947 - accuracy: 0.9682 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0899 - accuracy: 0.9696WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 55s 111ms/step - loss: 0.0899 - accuracy: 0.9696 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0804 - accuracy: 0.9728WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 55s 111ms/step - loss: 0.0804 - accuracy: 0.9728 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0757 - accuracy: 0.9749WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 55s 111ms/step - loss: 0.0757 - accuracy: 0.9749 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0722 - accuracy: 0.9757WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 55s 111ms/step - loss: 0.0722 - accuracy: 0.9757 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0583 - accuracy: 0.9804WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 55s 110ms/step - loss: 0.0583 - accuracy: 0.9804 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0631 - accuracy: 0.9791WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 55s 111ms/step - loss: 0.0631 - accuracy: 0.9791 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0566 - accuracy: 0.9819WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 55s 111ms/step - loss: 0.0566 - accuracy: 0.9819 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0528 - accuracy: 0.9821WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 55s 110ms/step - loss: 0.0528 - accuracy: 0.9821 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0473 - accuracy: 0.9843WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 55s 110ms/step - loss: 0.0473 - accuracy: 0.9843 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0497 - accuracy: 0.9830WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 55s 111ms/step - loss: 0.0497 - accuracy: 0.9830 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0458 - accuracy: 0.9851WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 55s 111ms/step - loss: 0.0458 - accuracy: 0.9851 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0475 - accuracy: 0.9838WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 111ms/step - loss: 0.0475 - accuracy: 0.9838 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0403 - accuracy: 0.9861WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 111ms/step - loss: 0.0403 - accuracy: 0.9861 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0365 - accuracy: 0.9884WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 55s 111ms/step - loss: 0.0365 - accuracy: 0.9884 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0398 - accuracy: 0.9867WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 111ms/step - loss: 0.0398 - accuracy: 0.9867 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0346 - accuracy: 0.9875WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 55s 111ms/step - loss: 0.0346 - accuracy: 0.9875 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0335 - accuracy: 0.9892WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 55s 111ms/step - loss: 0.0335 - accuracy: 0.9892 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 0.9885WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 55s 111ms/step - loss: 0.0342 - accuracy: 0.9885 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0325 - accuracy: 0.9887WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 55s 111ms/step - loss: 0.0325 - accuracy: 0.9887 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0308 - accuracy: 0.9895WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 55s 111ms/step - loss: 0.0308 - accuracy: 0.9895 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0250 - accuracy: 0.9917WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 55s 111ms/step - loss: 0.0250 - accuracy: 0.9917 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 0.9914WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 111ms/step - loss: 0.0256 - accuracy: 0.9914 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 0.9896WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 111ms/step - loss: 0.0311 - accuracy: 0.9896 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0306 - accuracy: 0.9899WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 111ms/step - loss: 0.0306 - accuracy: 0.9899 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0251 - accuracy: 0.9920WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 111ms/step - loss: 0.0251 - accuracy: 0.9920 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0273 - accuracy: 0.9908WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0273 - accuracy: 0.9908 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.9942WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 111ms/step - loss: 0.0171 - accuracy: 0.9942 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0233 - accuracy: 0.9920WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0233 - accuracy: 0.9920 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0233 - accuracy: 0.9921WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0233 - accuracy: 0.9921 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0274 - accuracy: 0.9908WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 111ms/step - loss: 0.0274 - accuracy: 0.9908 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 0.9939WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 111ms/step - loss: 0.0189 - accuracy: 0.9939 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 0.9932WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 111ms/step - loss: 0.0203 - accuracy: 0.9932 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9946WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 111ms/step - loss: 0.0168 - accuracy: 0.9946 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 0.9944WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 111ms/step - loss: 0.0166 - accuracy: 0.9944 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0244 - accuracy: 0.9920WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0244 - accuracy: 0.9920 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9938WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 111ms/step - loss: 0.0177 - accuracy: 0.9938 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 0.9951WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 111ms/step - loss: 0.0158 - accuracy: 0.9951 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 0.9939WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 111ms/step - loss: 0.0195 - accuracy: 0.9939 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.9942WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 111ms/step - loss: 0.0172 - accuracy: 0.9942 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.9945WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 111ms/step - loss: 0.0154 - accuracy: 0.9945 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 0.9961WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0112 - accuracy: 0.9961 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.9946WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 111ms/step - loss: 0.0172 - accuracy: 0.9946 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9950WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0153 - accuracy: 0.9950 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 0.9949WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0140 - accuracy: 0.9949 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9964WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0111 - accuracy: 0.9964 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 0.9933WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 111ms/step - loss: 0.0203 - accuracy: 0.9933 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9956WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0126 - accuracy: 0.9956 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9959WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 111ms/step - loss: 0.0123 - accuracy: 0.9959 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9963WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0111 - accuracy: 0.9963 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9968WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0093 - accuracy: 0.9968 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.9956WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0134 - accuracy: 0.9956 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9968WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0093 - accuracy: 0.9968 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.9970WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0102 - accuracy: 0.9970 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.9977WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0080 - accuracy: 0.9977 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9964WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0116 - accuracy: 0.9964 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9963WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 111ms/step - loss: 0.0109 - accuracy: 0.9963 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.9965WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0104 - accuracy: 0.9965 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.9969WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0102 - accuracy: 0.9969 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9968WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0106 - accuracy: 0.9968 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9964WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0109 - accuracy: 0.9964 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 0.9968WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 111ms/step - loss: 0.0088 - accuracy: 0.9968 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.9972WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0097 - accuracy: 0.9972 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.9980WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0065 - accuracy: 0.9980 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9982WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 111ms/step - loss: 0.0058 - accuracy: 0.9982 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.9960WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 113ms/step - loss: 0.0131 - accuracy: 0.9960 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9979WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0063 - accuracy: 0.9979 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9960WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0121 - accuracy: 0.9960 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 0.9966WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0099 - accuracy: 0.9966 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.9968WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0100 - accuracy: 0.9968 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9962WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0114 - accuracy: 0.9962 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.9975WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 113ms/step - loss: 0.0072 - accuracy: 0.9975 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9973WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0086 - accuracy: 0.9973 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 0.9952WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0139 - accuracy: 0.9952 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9972WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0092 - accuracy: 0.9972 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9975WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0069 - accuracy: 0.9975 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9982WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0058 - accuracy: 0.9982 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9984WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0051 - accuracy: 0.9984 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.9978WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "500/500 [==============================] - 56s 112ms/step - loss: 0.0065 - accuracy: 0.9978 - lr: 0.0010\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa20fa51390>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NN_EMRa6EaRc"
      },
      "source": [
        ""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rns1_taWDtYs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b5587e3-9f53-4f26-aded-4de034c274a2"
      },
      "source": [
        "scores = model_1.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 9s 25ms/step - loss: 0.9068 - accuracy: 0.8578\n",
            "Test loss: 0.9067997336387634\n",
            "Test accuracy: 0.8578000068664551\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIXviihiBV0k",
        "outputId": "837c27b5-e06e-4d07-e362-0c771c2c6026"
      },
      "source": [
        "scores = model_1.evaluate(x_train, y_train, verbose=1)\n",
        "print('loss:', scores[0])\n",
        "print('accuracy:', scores[1])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1094/1094 [==============================] - 26s 24ms/step - loss: 0.0191 - accuracy: 0.9941\n",
            "loss: 0.01913067325949669\n",
            "accuracy: 0.9941428303718567\n"
          ]
        }
      ]
    }
  ]
}